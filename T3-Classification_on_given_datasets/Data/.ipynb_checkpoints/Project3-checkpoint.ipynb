{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e70e76-de0b-4a1a-932c-262671f7e06c",
   "metadata": {},
   "source": [
    "# Data Mining Project3: Classification on Given Dataset \n",
    "- e-mail: niejy20@lzu.edu.cn\n",
    "- data：May 17th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f08b221-c983-49ee-9b04-065212f6e87e",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e53319-b0ab-4749-9ef6-45e9c90d263a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.1 数据集简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0ce53-b394-4771-9077-1a7b4d75098c",
   "metadata": {},
   "source": [
    "### GSE235508 转录组数据集\n",
    "\n",
    "- **数据来源**：来自类风湿关节炎（RA）、系统性红斑狼疮（SLE）患者及健康孕妇的血液转录组数据，旨在分析妊娠期免疫调节的基因表达差异。\n",
    "- **分类任务**：将样本分为不同组别（如 `HEALTHY`、`SPRA`、`SLE`），属于多分类问题（具体类别需根据 `samplegroup:ch1` 的取值确定）。\n",
    "- **数据规模**：包含 **335 个样本**，每个样本有 **60,218 个基因表达特征**（CPM 值），属于典型的高维小样本数据。\n",
    "- **特征特点**：特征为基因表达量，需进行标准化处理（如 log 转换），且存在大量零值或低方差基因，需进行特征筛选。\n",
    "\n",
    "---\n",
    "\n",
    "### 数据集对比\n",
    "- 在第一次作业中，我使用了数据挖掘领域较为经典的数据集：Breast Cancer Wisconsin，与本次作业的数据集同样应用于医学领域，这两个数据集的区别如下：\n",
    "\n",
    "| 特征                  | GSE235508 转录组数据集       | Breast Cancer Wisconsin 数据集 |\n",
    "|-----------------------|------------------------------|---------------------------------|\n",
    "| **数据量**            | 335 个样本                   | 569 个样本                      |\n",
    "| **特征数量**          | 60,218 个基因表达特征        | 30 个形态学特征                 |\n",
    "| **应用领域**          | 自身免疫疾病研究             | 乳腺癌医学诊断                  |\n",
    "| **分类任务**          | 多分类（疾病状态分组）       | 二分类（良性 vs 恶性）          \n",
    "| **数据挑战**          | 高维度、小样本、特征稀疏     | 小样本、特征可解释性高          |\n",
    "| **典型预处理方法**    | 标准化、特征选择、降维       | 标准化、特征相关性分析          |\n",
    "\n",
    "---\n",
    "\n",
    "### 对比分析\n",
    "\n",
    "1. **数据维度差异**  \n",
    "   - GSE235508 的特征数量（60k+）远超 Breast Cancer（30），需采用策略避免维度灾难（**PCA、t-SNE 或 LASSO 特征选择**等） 。\n",
    "   - 与 Breast Cancer 数据集相比，GSE235508 的样本量更小，但特征维度更高，容易导致模型过拟合。\n",
    "\n",
    "2. **领域特异性**  \n",
    "   - **医学转录组数据** 的基因表达特征具有生物学意义，但需结合通路分析（如 GSEA）增强可解释性。\n",
    "   - 不同于 MiniBooNE 的物理信号，基因表达数据通常需 **log 转换** 和 **批次效应校正**。\n",
    "\n",
    "---\n",
    "\n",
    "通过对比可见，GSE235508 的 **高维小样本特性** 为数据挖掘带来了挑战。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fa1d59-5f54-492b-b909-4869e2aef936",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.2 分类算法简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa4ae3-9001-4ed6-987e-ca0c71c4355b",
   "metadata": {},
   "source": [
    "分类算法可以根据不同的特点和学习方式来进行区分。以下是4种常见的分类方式："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c395d1-1c07-441b-b30a-0cd9519c89f3",
   "metadata": {},
   "source": [
    "### 一、基于学习方式\n",
    "\n",
    "| 分类依据 | 常见算法 | 特点 |\n",
    "| --- | --- | --- |\n",
    "| 监督学习 | 决策树、逻辑回归、支持向量机、朴素贝叶斯等 | 从带标签的数据中学习，映射函数将输入数据映射到已知的输出标签 |\n",
    "| 无监督学习 | k-均值聚类、层次聚类、高斯混合模型等 | 不依赖标记的训练数据，可以对数据进行聚类或降维等操作 |\n",
    "| 半监督学习 | 自训练算法、多视图训练算法等 | 结合少量有标签数据和大量无标签数据进行学习，通过无标签数据来提高模型的性能 |\n",
    "| 强化学习 | Q-learning、策略梯度方法等 | 通过与环境的交互来学习最优的行为策略，以最大化累积奖励 |\n",
    "\n",
    "### 二、基于模型复杂度\n",
    "\n",
    "| 分类依据 | 常见算法 | 特点 |\n",
    "| --- | --- | --- |\n",
    "| 简单模型 | 逻辑回归、决策树桩等 | 结构简单，训练和预测速度快，易于理解和解释，适用于数据规模较小或特征较少的情况 |\n",
    "| 集成模型 | 随机森林、AdaBoost、梯度提升树、XGBoost等 | 组合多个弱学习器以构建强大的模型，能够提高模型的准确性和泛化能力，但模型复杂度较高，训练和预测时间较长 |\n",
    "\n",
    "### 三、基于数据特点\n",
    "\n",
    "| 分类依据 | 常见算法 | 特点 |\n",
    "| --- | --- | --- |\n",
    "| 线性可分数据 | 逻辑回归、线性支持向量机等 | 适用于数据在特征空间中线性可分的情况，通过寻找一个线性决策边界来区分不同类别的样本 |\n",
    "| 非线性数据 | 决策树、支持向量机（非线性核函数）、神经网络等 | 适用于数据在特征空间中非线性可分的情况，能够学习复杂的非线性决策边界 |\n",
    "\n",
    "### 四、基于模型可解释性\n",
    "\n",
    "| 分类依据 | 常见算法 | 特点 |\n",
    "| --- | --- | --- |\n",
    "| 可解释模型 | 决策树、逻辑回归等 | 模型的决策过程易于理解和解释，能够提供直观的特征重要性和决策规则 |\n",
    "| 黑盒模型 | 神经网络、梯度提升树等 | 模型的内部结构和决策过程较为复杂，可解释性差，但通常具有较高的预测性能|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1620f50e-f298-44c0-987d-2206590c3de4",
   "metadata": {},
   "source": [
    "在本次project中，共使用了10种用于分类任务的算法，这些算法的特点如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22596f5f-b9ef-4019-9f0c-bf55dd2777a9",
   "metadata": {},
   "source": [
    "1. 随机森林 (Random Forest)：基于Bootstrap采样构建多棵决策树；通过投票/平均机制降低方差；可评估特征重要性。\n",
    "\n",
    "2. 支持向量机 (SVM)：通过核技巧处理非线性可分问题；最大化分类间隔提升泛化能力；对高维数据表现优异。\n",
    "\n",
    "3. Lasso回归：L1正则化产生稀疏解实现特征选择；对多重共线性数据具有鲁棒性。\n",
    "\n",
    "4. XGBoost/LightGBM：基于梯度提升框架的优化实现；支持自定义损失函数与评估指标；提供早停机制防止过拟合。\n",
    "\n",
    "5. 弹性网络 (Elastic Net)：结合L1和L2正则化优势；在特征选择与系数稳定性间取得平衡。\n",
    "\n",
    "6. 偏最小二乘判别分析 (PLS-DA)：通过潜变量提取实现降维；有效处理多变量共线性问题。\n",
    "\n",
    "7. 神经网络 (MLP)：通过隐藏层学习非线性表示；对数据规模与质量敏感。\n",
    "\n",
    "8. 朴素贝叶斯 (Naive Bayes)：计算效率高适合实时预测；对缺失数据不敏感；特征相关性较强时性能下降。\n",
    "\n",
    "9. 最近邻分类 (KNN)：基于样本空间距离度量；对噪声数据和维度灾难敏感；需优化距离度量与k值选择。\n",
    "\n",
    "10. 集成特征选择方法：融合过滤式/包裹式/嵌入式方法优势；通过多模型投票提升稳定性；降低单一方法偏差风险；但可能增加计算复杂度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211dce1f-1a10-418a-a3c3-ce6054289b02",
   "metadata": {},
   "source": [
    "# 2. Classification (10 algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f504394b-a203-4a79-bc4a-6abf0d9620b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, SelectFromModel, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b67639c-21e8-4f73-b8e7-d78be096e8b3",
   "metadata": {},
   "source": [
    "## 2.1 RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31132894-cea8-486b-9a76-f9c9d0704039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (335, 60220)\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      "=== 模型性能评估 ===\n",
      "              Train      Test\n",
      "Accuracy   0.771605  0.373134\n",
      "Precision  0.776515  0.413866\n",
      "Recall     0.771605  0.373134\n",
      "F1         0.769656  0.379225\n",
      "\n",
      "=== 测试集详细分类报告 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.58      0.50        19\n",
      "           1       0.67      0.40      0.50        20\n",
      "           2       0.14      0.22      0.17         9\n",
      "           3       0.25      0.21      0.23        19\n",
      "\n",
      "    accuracy                           0.37        67\n",
      "   macro avg       0.37      0.35      0.35        67\n",
      "weighted avg       0.41      0.37      0.38        67\n",
      "\n",
      "\n",
      "=== Top 10重要基因 ===\n",
      "                gene  importance\n",
      "436  ENSG00000256128    0.231645\n",
      "207  ENSG00000165887    0.226882\n",
      "76   ENSG00000119906    0.152780\n",
      "128  ENSG00000137877    0.147168\n",
      "109  ENSG00000134283    0.140211\n",
      "77   ENSG00000119913    0.137613\n",
      "239  ENSG00000172971    0.108621\n",
      "103  ENSG00000132182    0.103483\n",
      "261  ENSG00000181092    0.085516\n",
      "275  ENSG00000185551    0.084107\n"
     ]
    }
   ],
   "source": [
    "# 加载元数据（使用geo_accession）\n",
    "meta = pd.read_csv(\n",
    "    \"./Data/GSE235508.meta.txt\",\n",
    "    sep='\\t',\n",
    "    quotechar='\"',\n",
    "    encoding='utf-8',\n",
    "    dtype=str\n",
    ")\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "# 加载表达数据\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "# 合并数据\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "print(f\"Merged shape: {merged.shape}\")  # 应输出(335, 60220)\n",
    "\n",
    "# 特征矩阵和目标变量\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)  # 确保数值类型\n",
    "y = merged['group']\n",
    "\n",
    "# 标签编码\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 数据预处理管道\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # 中位数填充缺失值\n",
    "    ('variance_filter', VarianceThreshold(threshold=0.1*(1-0.1))),  # 移除低方差特征\n",
    "    ('selector', SelectKBest(f_classif, k=500)),  # 选择top k个差异基因\n",
    "    ('pca', PCA(n_components=0.95)),  # 保留95%方差的主成分\n",
    "])\n",
    "\n",
    "# 划分训练测试集（先预处理再划分）\n",
    "X_preprocessed = preprocessor.fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 处理类别不平衡（仅在训练集应用SMOTE）\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=10)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 构建随机森林模型管道\n",
    "rf_pipeline = Pipeline([\n",
    "    ('rf', RandomForestClassifier(max_depth=10, min_samples_leaf=5))\n",
    "])\n",
    "\n",
    "# 超参数网格搜索\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__max_depth': [None, 10, 20],\n",
    "    'rf__min_samples_split': [2, 5],\n",
    "    'rf__max_features': ['sqrt', 0.5],\n",
    "    'rf__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision_weighted': make_scorer(precision_score, average='weighted'),\n",
    "    'recall_weighted': make_scorer(recall_score, average='weighted'),\n",
    "    'f1_weighted': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1_weighted',  # 用f1选择最佳模型\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True  # 返回训练集指标\n",
    ")\n",
    "\n",
    "# 训练与调优\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 生成详细评估报告\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"输出多指标评估报告\"\"\"\n",
    "    # 训练集预测\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    # 测试集预测\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # 计算指标\n",
    "    metrics = {\n",
    "        'Train': {\n",
    "            'Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "            'Precision': precision_score(y_train, y_train_pred, average='weighted'),\n",
    "            'Recall': recall_score(y_train, y_train_pred, average='weighted'),\n",
    "            'F1': f1_score(y_train, y_train_pred, average='weighted')\n",
    "        },\n",
    "        'Test': {\n",
    "            'Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "            'Precision': precision_score(y_test, y_test_pred, average='weighted'),\n",
    "            'Recall': recall_score(y_test, y_test_pred, average='weighted'),\n",
    "            'F1': f1_score(y_test, y_test_pred, average='weighted')\n",
    "        }\n",
    "    }\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# 执行评估\n",
    "metrics_df = evaluate_model(best_model, X_train_res, y_train_res, X_test, y_test)\n",
    "\n",
    "# 打印指标表格\n",
    "print(\"\\n=== 模型性能评估 ===\")\n",
    "print(metrics_df)\n",
    "\n",
    "# 打印分类报告\n",
    "print(\"\\n=== 测试集详细分类报告 ===\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))\n",
    "\n",
    "# 保存评估结果\n",
    "metrics_df.to_csv('model_metrics_randomForest.csv', index=True)\n",
    "\n",
    "# 特征重要性分析\n",
    "# 获取特征选择后的基因索引\n",
    "selected_idx = preprocessor.named_steps['selector'].get_support(indices=True)\n",
    "feature_names = X.columns[selected_idx]\n",
    "\n",
    "# 获取PCA前的特征重要性\n",
    "importances = best_model.named_steps['rf'].feature_importances_\n",
    "pca_components = preprocessor.named_steps['pca'].components_\n",
    "\n",
    "# 映射回原始特征空间\n",
    "raw_importances = np.abs(pca_components.T @ importances).flatten()\n",
    "\n",
    "# 创建重要性DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'gene': feature_names,\n",
    "    'importance': raw_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== Top 10重要基因 ===\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1f659-6af4-425a-a1aa-9bc2d3b4362c",
   "metadata": {},
   "source": [
    "## 2.2 SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77921e15-0585-432e-bfbc-8a4b77a76c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "\n",
      "=== 模型性能评估 ===\n",
      "              Train      Test\n",
      "Accuracy   0.993827  0.865672\n",
      "Precision  0.993976  0.869689\n",
      "Recall     0.993827  0.865672\n",
      "F1         0.993826  0.863294\n",
      "\n",
      "=== 测试集详细分类报告 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        19\n",
      "           1       0.94      0.80      0.86        20\n",
      "           2       0.75      0.67      0.71         9\n",
      "           3       0.83      1.00      0.90        19\n",
      "\n",
      "    accuracy                           0.87        67\n",
      "   macro avg       0.85      0.84      0.84        67\n",
      "weighted avg       0.87      0.87      0.86        67\n",
      "\n",
      "Top 10重要基因（线性核）:\n",
      "                gene  importance\n",
      "499  ENSG00000277051    0.216260\n",
      "176  ENSG00000156256    0.128482\n",
      "452  ENSG00000261609    0.116064\n",
      "211  ENSG00000166948    0.114617\n",
      "265  ENSG00000182351    0.110273\n",
      "297  ENSG00000196504    0.103458\n",
      "364  ENSG00000228073    0.102173\n",
      "182  ENSG00000158458    0.101446\n",
      "343  ENSG00000211801    0.098121\n",
      "302  ENSG00000197483    0.093494\n"
     ]
    }
   ],
   "source": [
    "# 数据加载与合并（与原始代码一致）\n",
    "meta = pd.read_csv(\n",
    "    \"./Data/GSE235508.meta.txt\",\n",
    "    sep='\\t',\n",
    "    quotechar='\"',\n",
    "    encoding='utf-8',\n",
    "    dtype=str\n",
    ")\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)\n",
    "y = merged['group']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 增加标准化步骤\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('variance_filter', VarianceThreshold(threshold=0.1*(1-0.1))),\n",
    "    ('selector', SelectKBest(f_classif, k=500)),\n",
    "    ('scaler', StandardScaler()),  # SVC需要特征标准化\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "])\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=10)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "svc_pipeline = Pipeline([\n",
    "    ('svc', SVC(probability=True, decision_function_shape='ovr'))  # 启用概率估计\n",
    "])\n",
    "\n",
    "# 调整SVC参数\n",
    "param_grid = {\n",
    "    'svc__C': [0.1, 1, 10],  # 正则化参数\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'svc__gamma': ['scale', 'auto'],  # 仅对非线性核有效\n",
    "    'svc__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svc_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 执行评估\n",
    "metrics_df = evaluate_model(best_model, X_train_res, y_train_res, X_test, y_test)\n",
    "\n",
    "# 打印指标表格\n",
    "print(\"\\n=== 模型性能评估 ===\")\n",
    "print(metrics_df)\n",
    "\n",
    "# 打印分类报告\n",
    "print(\"\\n=== 测试集详细分类报告 ===\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))\n",
    "\n",
    "# 保存评估结果\n",
    "metrics_df.to_csv('model_metrics_svc.csv', index=True)\n",
    "\n",
    "# 特征重要性分析（仅适用于线性核）\n",
    "if best_model.named_steps['svc'].kernel == 'linear':\n",
    "    coef = best_model.named_steps['svc'].coef_\n",
    "    pca_components = preprocessor.named_steps['pca'].components_\n",
    "    \n",
    "    raw_importances = np.abs(pca_components.T @ coef.mean(axis=0)).flatten()\n",
    "    \n",
    "    selected_idx = preprocessor.named_steps['selector'].get_support(indices=True)\n",
    "    feature_names = X.columns[selected_idx]\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'gene': feature_names,\n",
    "        'importance': raw_importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"Top 10重要基因（线性核）:\")\n",
    "    print(importance_df.head(10))\n",
    "else:\n",
    "    print(\"特征重要性分析仅适用于线性核\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af0041-684b-493b-aa96-9f1f4a77e311",
   "metadata": {},
   "source": [
    "## 2.3 Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44503ada-dfac-4b36-9abb-8bc650e57d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best Parameters: {'lr__C': 10.0}\n",
      "Train F1: 1.000\n",
      "Test F1: 0.910\n",
      "\n",
      "=== 模型性能评估 ===\n",
      "           Train      Test\n",
      "Accuracy     1.0  0.910448\n",
      "Precision    1.0  0.911676\n",
      "Recall       1.0  0.910448\n",
      "F1           1.0  0.910015\n",
      "\n",
      "=== 测试集详细分类报告 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92        19\n",
      "           1       0.95      0.90      0.92        20\n",
      "           2       0.78      0.78      0.78         9\n",
      "           3       0.90      1.00      0.95        19\n",
      "\n",
      "    accuracy                           0.91        67\n",
      "   macro avg       0.89      0.89      0.89        67\n",
      "weighted avg       0.91      0.91      0.91        67\n",
      "\n",
      "Top 10重要基因:\n",
      "                gene  importance\n",
      "370  ENSG00000229395    0.015261\n",
      "470  ENSG00000265980    0.012589\n",
      "347  ENSG00000216859    0.011801\n",
      "354  ENSG00000222419    0.011293\n",
      "499  ENSG00000277051    0.010831\n",
      "302  ENSG00000197483    0.010576\n",
      "386  ENSG00000233286    0.009177\n",
      "379  ENSG00000231064    0.009092\n",
      "265  ENSG00000182351    0.009090\n",
      "314  ENSG00000199701    0.008880\n"
     ]
    }
   ],
   "source": [
    "# 数据加载\n",
    "meta = pd.read_csv(\n",
    "    \"./Data/GSE235508.meta.txt\",\n",
    "    sep='\\t',\n",
    "    quotechar='\"',\n",
    "    encoding='utf-8',\n",
    "    dtype=str\n",
    ")\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)\n",
    "y = merged['group']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 数据预处理管道\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('variance_filter', VarianceThreshold(threshold=0.1*(1-0.1))),\n",
    "    ('selector', SelectKBest(f_classif, k=500)),\n",
    "    ('scaler', StandardScaler()),  # 必须标准化\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "])\n",
    "\n",
    "# 划分训练测试集、处理类别不平衡\n",
    "X_preprocessed = preprocessor.fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=10)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 构建Lasso逻辑回归模型\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('lr', LogisticRegression(\n",
    "        penalty='l1',  # L1正则化\n",
    "        solver='saga',  # 唯一支持L1+多分类的求解器\n",
    "        max_iter=10000,  \n",
    "        tol=5e-4\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'lr__C': np.logspace(-3, 2, 6),  # 正则化强度：0.001到100\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lasso_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Train F1: {best_model.score(X_train_res, y_train_res):.3f}\")\n",
    "print(f\"Test F1: {best_model.score(X_test, y_test):.3f}\")\n",
    "\n",
    "metrics_df = evaluate_model(best_model, X_train_res, y_train_res, X_test, y_test)\n",
    "\n",
    "# 打印指标表格\n",
    "print(\"\\n=== 模型性能评估 ===\")\n",
    "print(metrics_df)\n",
    "\n",
    "# 打印分类报告\n",
    "print(\"\\n=== 测试集详细分类报告 ===\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))\n",
    "\n",
    "# 保存评估结果\n",
    "metrics_df.to_csv('model_metrics_lasso.csv', index=True)\n",
    "\n",
    "coef_matrix = best_model.named_steps['lr'].coef_\n",
    "pca_components = preprocessor.named_steps['pca'].components_\n",
    "\n",
    "# 映射回原始特征空间（对各类别系数取平均）\n",
    "raw_importances = np.abs(pca_components.T @ coef_matrix.mean(axis=0)).flatten()\n",
    "\n",
    "selected_idx = preprocessor.named_steps['selector'].get_support(indices=True)\n",
    "feature_names = X.columns[selected_idx]\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'gene': feature_names,\n",
    "    'importance': raw_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10重要基因:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed99fa3c-ce76-4e5d-bd47-304236da9d83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tips.收敛警告\n",
    "构建Lasso回归模型时，下列两个参数设置不合适可能会导致收敛警告：\n",
    "\n",
    "- max_iter=1000, \n",
    "- tol=1e-4\n",
    "\n",
    "C:\\Users\\20187\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
    "warnings.warn(\n",
    "\n",
    "原因：1.迭代次数不足（max_iter 设置过小）、2.敛容差过严（tol 设置过小）\n",
    "\n",
    "将迭代次数增加至10000、收敛阈值减半，警告消失。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b77f85-ddf0-4dcf-be5a-4b467e878419",
   "metadata": {},
   "source": [
    "## 2.4 XGBoost/LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6245855-5ad3-4aaf-b06d-7d36db82ed8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "Best Parameters: {'xgb__colsample_bytree': 0.8, 'xgb__gamma': 0, 'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100, 'xgb__subsample': 0.8}\n",
      "Train F1: 0.833\n",
      "Test F1: 0.463\n",
      "\n",
      "=== 模型性能评估 ===\n",
      "              Train      Test\n",
      "Accuracy   0.833333  0.462687\n",
      "Precision  0.839090  0.515355\n",
      "Recall     0.833333  0.462687\n",
      "F1         0.833005  0.480522\n",
      "\n",
      "=== 测试集详细分类报告 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.53      0.54        19\n",
      "           1       0.71      0.50      0.59        20\n",
      "           2       0.19      0.33      0.24         9\n",
      "           3       0.42      0.42      0.42        19\n",
      "\n",
      "    accuracy                           0.46        67\n",
      "   macro avg       0.47      0.45      0.45        67\n",
      "weighted avg       0.52      0.46      0.48        67\n",
      "\n",
      "Top 10重要基因:\n",
      "                gene  importance\n",
      "436  ENSG00000256128    0.262557\n",
      "207  ENSG00000165887    0.227562\n",
      "128  ENSG00000137877    0.135058\n",
      "76   ENSG00000119906    0.128651\n",
      "109  ENSG00000134283    0.119066\n",
      "77   ENSG00000119913    0.104919\n",
      "103  ENSG00000132182    0.094561\n",
      "239  ENSG00000172971    0.094392\n",
      "261  ENSG00000181092    0.078703\n",
      "169  ENSG00000152457    0.071048\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='xgboost')\n",
    "\n",
    "# 1. 数据加载与合并（保持原有流程）\n",
    "meta = pd.read_csv(\n",
    "    \"./Data/GSE235508.meta.txt\",\n",
    "    sep='\\t',\n",
    "    quotechar='\"',\n",
    "    encoding='utf-8',\n",
    "    dtype=str\n",
    ")\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)\n",
    "y = merged['group']\n",
    "\n",
    "# 2. 标签编码（XGBoost需要从0开始的整数类别）\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 3. 数据预处理管道（移除标准化，树模型不需要）\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('variance_filter', VarianceThreshold(threshold=0.1*(1-0.1))),\n",
    "    ('selector', SelectKBest(f_classif, k=500)),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "])\n",
    "\n",
    "# 4. 划分训练测试集\n",
    "X_preprocessed = preprocessor.fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 5. 处理类别不平衡（XGBoost支持样本权重，但保持SMOTE流程）\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=10)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 6. 构建XGBoost模型管道\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('xgb', XGBClassifier(\n",
    "        objective='multi:softmax',  # 多分类目标函数\n",
    "        n_jobs=-1,\n",
    "        eval_metric='mlogloss',     # 多分类对数损失\n",
    "        early_stopping_rounds=10,   # 早停机制\n",
    "        use_label_encoder=False     # 禁用旧版标签编码\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 7. 超参数网格搜索\n",
    "param_grid = {\n",
    "    'xgb__n_estimators': [100, 200],\n",
    "    'xgb__max_depth': [3, 5, 7],\n",
    "    'xgb__learning_rate': [0.01, 0.1],\n",
    "    'xgb__subsample': [0.8, 1.0],\n",
    "    'xgb__colsample_bytree': [0.8, 1.0],\n",
    "    'xgb__gamma': [0, 0.1],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 8. 训练与调优（添加验证集用于早停）\n",
    "grid_search.fit(\n",
    "    X_train_res, y_train_res,\n",
    "    xgb__eval_set=[(X_test, y_test)],  # 早停监控验证集\n",
    "    xgb__verbose=False\n",
    ")\n",
    "\n",
    "# 9. 评估最佳模型\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.named_steps['xgb'].set_params(verbosity=0)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Train F1: {best_model.score(X_train_res, y_train_res):.3f}\")\n",
    "print(f\"Test F1: {best_model.score(X_test, y_test):.3f}\")\n",
    "\n",
    "metrics_df = evaluate_model(best_model, X_train_res, y_train_res, X_test, y_test)\n",
    "\n",
    "# 打印指标表格\n",
    "print(\"\\n=== 模型性能评估 ===\")\n",
    "print(metrics_df)\n",
    "\n",
    "# 打印分类报告\n",
    "print(\"\\n=== 测试集详细分类报告 ===\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))\n",
    "\n",
    "# 保存评估结果\n",
    "metrics_df.to_csv('model_metrics_xgb.csv', index=True)\n",
    "\n",
    "# 11. 特征重要性分析（基于树模型内置重要性）\n",
    "selected_idx = preprocessor.named_steps['selector'].get_support(indices=True)\n",
    "feature_names = X.columns[selected_idx]\n",
    "\n",
    "importances = best_model.named_steps['xgb'].feature_importances_\n",
    "pca_components = preprocessor.named_steps['pca'].components_\n",
    "\n",
    "raw_importances = np.abs(pca_components.T @ importances).flatten()\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'gene': feature_names,\n",
    "    'importance': raw_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10重要基因:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9751466-1c86-4f6a-8fd8-657604b3f38a",
   "metadata": {},
   "source": [
    "## 2.5 Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "149ec754-e318-4423-927f-ccd4507baaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
      "\n",
      "=== 模型性能评估 ===\n",
      "           Train      Test\n",
      "Accuracy     1.0  0.895522\n",
      "Precision    1.0  0.905076\n",
      "Recall       1.0  0.895522\n",
      "F1           1.0  0.895945\n",
      "\n",
      "=== 测试集详细分类报告 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92        19\n",
      "           1       1.00      0.85      0.92        20\n",
      "           2       0.78      0.78      0.78         9\n",
      "           3       0.83      1.00      0.90        19\n",
      "\n",
      "    accuracy                           0.90        67\n",
      "   macro avg       0.89      0.88      0.88        67\n",
      "weighted avg       0.91      0.90      0.90        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# 数据加载与预处理（保持原流程）\n",
    "meta = pd.read_csv(\"./Data/GSE235508.meta.txt\", sep='\\t', dtype=str)\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)\n",
    "y = merged['group']\n",
    "\n",
    "# 标签编码\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 优化后的预处理流程\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('variance_filter', VarianceThreshold(threshold=0.1*(1-0.1))),\n",
    "    ('scaler', StandardScaler()),  # 新增标准化步骤\n",
    "    ('feature_selector', SelectKBest(score_func=f_classif, k=1000))\n",
    "])\n",
    "\n",
    "# 数据预处理\n",
    "X_preprocessed = preprocessor.fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 处理类别不平衡\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=5)  # 调整k_neighbors\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 构建Elastic Net模型管道\n",
    "en_pipeline = Pipeline([\n",
    "    ('en', LogisticRegression(\n",
    "        penalty='elasticnet',\n",
    "        solver='saga',\n",
    "        multi_class='multinomial',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 弹性网络专用超参数网格\n",
    "param_grid = {\n",
    "    'en__C': np.logspace(-3, 3, 7),  # 正则化强度倒数\n",
    "    'en__l1_ratio': [0.1, 0.5, 0.9]  # L1/L2混合比例\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision_weighted': make_scorer(precision_score, average='weighted'),\n",
    "    'recall_weighted': make_scorer(recall_score, average='weighted'),\n",
    "    'f1_weighted': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=en_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1_weighted',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# 训练与调优\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 执行评估\n",
    "best_model = grid_search.best_estimator_\n",
    "metrics_df = evaluate_model(best_model, X_train_res, y_train_res, X_test, y_test)\n",
    "\n",
    "# 输出结果\n",
    "print(\"\\n=== 模型性能评估 ===\")\n",
    "print(metrics_df)\n",
    "print(\"\\n=== 测试集详细分类报告 ===\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dbf036-8e46-4731-b55e-08227d611438",
   "metadata": {},
   "source": [
    "## 2.6 PLS-DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b13e82b5-d9a6-4b51-bafd-781b7b078ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "=== 模型性能评估 ===\n",
      "              Train      Test\n",
      "Accuracy   0.484568  0.388060\n",
      "Precision  0.525499  0.488906\n",
      "Recall     0.484568  0.388060\n",
      "F1         0.459918  0.362701\n",
      "\n",
      "=== 测试集详细分类报告 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.05      0.10        19\n",
      "           1       0.62      0.40      0.48        20\n",
      "           2       0.21      0.67      0.32         9\n",
      "           3       0.48      0.58      0.52        19\n",
      "\n",
      "    accuracy                           0.39        67\n",
      "   macro avg       0.45      0.42      0.35        67\n",
      "weighted avg       0.49      0.39      0.36        67\n",
      "\n",
      "\n",
      "=== Top 10重要基因（VIP得分）===\n",
      "                gene  VIP_score\n",
      "175  ENSG00000197965   0.119924\n",
      "153  ENSG00000179071   0.112536\n",
      "268  ENSG00000272602   0.111722\n",
      "116  ENSG00000160932   0.110523\n",
      "69   ENSG00000133106   0.109513\n",
      "86   ENSG00000137965   0.108295\n",
      "261  ENSG00000268362   0.108250\n",
      "133  ENSG00000167633   0.108076\n",
      "85   ENSG00000137959   0.107600\n",
      "185  ENSG00000206127   0.106757\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "class PLSDAClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_components=2, scale=True):\n",
    "        self.n_components = n_components\n",
    "        self.scale = scale\n",
    "        self.pls = PLSRegression(n_components=n_components, scale=scale)\n",
    "        self.encoder = OneHotEncoder(sparse_output=False)\n",
    "        self.is_fitted_ = False  # 添加拟合状态标识\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        y_encoded = self.encoder.fit_transform(y.reshape(-1, 1))\n",
    "        self.pls.fit(X, y_encoded)\n",
    "        self.is_fitted_ = True  # 标记已拟合\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'is_fitted_')  # 添加状态检查\n",
    "        return np.argmax(self.pls.predict(X), axis=1)\n",
    "\n",
    "\n",
    "# 数据加载与预处理（保持原有流程）\n",
    "meta = pd.read_csv(\"./Data/GSE235508.meta.txt\", sep='\\t', dtype=str)\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)\n",
    "y = merged['group']\n",
    "\n",
    "# 标签编码\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 预处理管道（移除PCA，增加标准化）\n",
    "full_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('variance_filter', VarianceThreshold(threshold=0.1*(1-0.1))),\n",
    "    ('selector', SelectKBest(f_classif, k=500)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(sampling_strategy='auto', k_neighbors=5)),\n",
    "    ('plsda', PLSDAClassifier())\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,  # 使用原始X\n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 构建PLS-DA管道\n",
    "plsda_pipeline = Pipeline([\n",
    "    ('plsda', PLSDAClassifier())\n",
    "])\n",
    "\n",
    "# 超参数网格\n",
    "param_grid = {\n",
    "    'plsda__n_components': [2, 3],  # 根据样本量调整\n",
    "    'plsda__scale': [True]\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision_weighted': make_scorer(precision_score, average='weighted'),\n",
    "    'recall_weighted': make_scorer(recall_score, average='weighted'),\n",
    "    'f1_weighted': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "# 网格搜索\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=full_pipeline,  # 使用完整管道\n",
    "    param_grid={\n",
    "        'smote__k_neighbors': [3, 5],      # SMOTE参数调优\n",
    "        'plsda__n_components': [2, 3],     # PLS-DA参数\n",
    "        'selector__k': [300, 500]          # 特征选择参数\n",
    "    },\n",
    "    scoring=scoring,\n",
    "    refit='f1_weighted',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# 训练与调优\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 评估函数\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'Train': {\n",
    "            'Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "            'Precision': precision_score(y_train, y_train_pred, average='weighted'),\n",
    "            'Recall': recall_score(y_train, y_train_pred, average='weighted'),\n",
    "            'F1': f1_score(y_train, y_train_pred, average='weighted')\n",
    "        },\n",
    "        'Test': {\n",
    "            'Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "            'Precision': precision_score(y_test, y_test_pred, average='weighted'),\n",
    "            'Recall': recall_score(y_test, y_test_pred, average='weighted'),\n",
    "            'F1': f1_score(y_test, y_test_pred, average='weighted')\n",
    "        }\n",
    "    }\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# 执行评估\n",
    "best_model = grid_search.best_estimator_\n",
    "metrics_df = evaluate_model(best_model, X_train_res, y_train_res, X_test, y_test)\n",
    "\n",
    "# 输出结果\n",
    "print(\"\\n=== 模型性能评估 ===\")\n",
    "print(metrics_df)\n",
    "print(\"\\n=== 测试集详细分类报告 ===\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))\n",
    "\n",
    "# 特征重要性分析\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "selector_mask = best_pipeline.named_steps['selector'].get_support()\n",
    "variance_mask = best_pipeline.named_steps['variance_filter'].get_support()\n",
    "selected_features = X.columns[variance_mask][selector_mask]\n",
    "\n",
    "# 修改VIP计算函数\n",
    "def calculate_vip(model):\n",
    "    try:\n",
    "        t = model.x_scores_       # 得分矩阵 (n_samples, n_components)\n",
    "        w = model.x_weights_      # 权重矩阵 (n_features, n_components)\n",
    "        q = model.y_loadings_     # Y载荷 (n_classes, n_components)\n",
    "    except AttributeError as e:\n",
    "        raise RuntimeError(\"PLS模型未正确拟合，请先调用fit方法\") from e\n",
    "\n",
    "    # 计算每个成分的SSY贡献\n",
    "    ssy = np.sum(q**2 * np.sum(t**2, axis=0), axis=0)  # 修正为(n_components,)\n",
    "    total_ssy = ssy.sum()\n",
    "    \n",
    "    # 修正维度对齐问题\n",
    "    vip = np.sqrt(w.shape[1] * np.sum(ssy.reshape(1, -1) * (w**2), axis=1) / total_ssy)\n",
    "    return vip\n",
    "\n",
    "vip_scores = calculate_vip(best_pipeline.named_steps['plsda'].pls)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'gene': selected_features,\n",
    "    'VIP_score': vip_scores\n",
    "}).sort_values('VIP_score', ascending=False)\n",
    "\n",
    "print(\"\\n=== Top 10重要基因（VIP得分）===\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# 保存结果\n",
    "metrics_df.to_csv('model_metrics_plsda.csv', index=True)\n",
    "importance_df.to_csv('feature_importance_plsda.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013b5109-51b1-4761-839c-1a175650be1f",
   "metadata": {},
   "source": [
    "## 2.7 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95e97b2b-6f88-4b00-a830-1d73b6020867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 模型性能评估 ===\n",
      "           Train      Test\n",
      "Accuracy     1.0  0.910448\n",
      "Precision    1.0  0.915724\n",
      "Recall       1.0  0.910448\n",
      "F1           1.0  0.910695\n",
      "\n",
      "=== 最佳参数组合 ===\n",
      "{'mlpclassifier__activation': 'tanh', 'mlpclassifier__alpha': 0.001, 'mlpclassifier__dropout_rate': 0.5, 'mlpclassifier__hidden_layer_sizes': (256, 128), 'mlpclassifier__learning_rate_init': 0.0005, 'mlpclassifier__verbose': 0}\n",
      "\n",
      "=== 测试集详细分类报告 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92        19\n",
      "           1       1.00      0.90      0.95        20\n",
      "           2       0.78      0.78      0.78         9\n",
      "           3       0.86      1.00      0.93        19\n",
      "\n",
      "    accuracy                           0.91        67\n",
      "   macro avg       0.90      0.89      0.89        67\n",
      "weighted avg       0.92      0.91      0.91        67\n",
      "\n",
      "\n",
      "=== Top 10重要特征 ===\n",
      "             feature  importance\n",
      "121  ENSG00000110203    0.043147\n",
      "759  ENSG00000237541    0.040816\n",
      "673  ENSG00000216753    0.039380\n",
      "266  ENSG00000140450    0.038598\n",
      "24   ENSG00000049768    0.038390\n",
      "771  ENSG00000240403    0.038281\n",
      "438  ENSG00000169918    0.038029\n",
      "300  ENSG00000146021    0.037833\n",
      "614  ENSG00000200434    0.037770\n",
      "940  ENSG00000276471    0.037690\n"
     ]
    }
   ],
   "source": [
    "# 数据加载与预处理（保持原有流程）\n",
    "meta = pd.read_csv(\"./Data/GSE235508.meta.txt\", sep='\\t', dtype=str)\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)\n",
    "y = merged['group']\n",
    "\n",
    "# 标签编码\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 优化后的预处理流程\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('variance_filter', VarianceThreshold(threshold=0.1*(1-0.1))),\n",
    "    ('selector', SelectKBest(f_classif, k=1000)),  # 选择top 1000特征\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# 数据预处理\n",
    "X_preprocessed = preprocessor.fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 超参数网格（优化后的参数范围）\n",
    "param_grid = {\n",
    "    'mlpclassifier__verbose': [0],\n",
    "    'mlpclassifier__hidden_layer_sizes': [(512,), (256, 128)],\n",
    "    'mlpclassifier__activation': ['relu', 'tanh'],\n",
    "    'mlpclassifier__alpha': [0.0001, 0.001],\n",
    "    'mlpclassifier__learning_rate_init': [0.001, 0.0005],\n",
    "    'mlpclassifier__dropout_rate': [0.2, 0.5]  # 注意参数名称对应\n",
    "}\n",
    "\n",
    "class DropoutMLP(MLPClassifier):\n",
    "    \"\"\"带Dropout的自定义MLP\"\"\"\n",
    "    def __init__(self, \n",
    "                 dropout_rate=0.5,\n",
    "                 hidden_layer_sizes=(100,), \n",
    "                 activation=\"relu\",\n",
    "                 alpha=0.0001,\n",
    "                 learning_rate_init=0.001,\n",
    "                 batch_size=32,\n",
    "                 verbose=0,\n",
    "                 **kwargs):\n",
    "        # 显式声明父类参数\n",
    "        super().__init__(\n",
    "            hidden_layer_sizes=hidden_layer_sizes,\n",
    "            activation=activation,\n",
    "            alpha=alpha,\n",
    "            learning_rate_init=learning_rate_init,\n",
    "            batch_size=batch_size,\n",
    "            verbose=verbose,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def _forward(self, X, training=False):\n",
    "        # 保持原有实现不变\n",
    "        activations = []\n",
    "        layer_units = [X.shape[1]] + list(self.hidden_layer_sizes) + [self.n_outputs_]\n",
    "        for i in range(self.n_layers_ - 1):\n",
    "            activations.append(X)\n",
    "            X = self._activation(self.activation(X @ self.coefs_[i] + self.intercepts_[i]))\n",
    "            if training and i < self.n_layers_ - 2:\n",
    "                X = X * np.random.binomial(1, 1-self.dropout_rate, size=X.shape) / (1-self.dropout_rate)\n",
    "        activations.append(X)\n",
    "        return activations\n",
    "\n",
    "# 构建带SMOTE的MLP管道\n",
    "mlp_pipeline = make_pipeline(\n",
    "    SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42),\n",
    "    DropoutMLP(\n",
    "        batch_size=32,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# 更新管道使用自定义MLP\n",
    "mlp_pipeline.steps[-1] = ('mlpclassifier', DropoutMLP())\n",
    "\n",
    "# 评估指标\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision_weighted': make_scorer(precision_score, average='weighted'),\n",
    "    'recall_weighted': make_scorer(recall_score, average='weighted'),\n",
    "    'f1_weighted': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "# 配置网格搜索\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=mlp_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1_weighted',\n",
    "    cv=3,\n",
    "    n_jobs=1,  # 神经网络并行可能有问题\n",
    "    verbose=0,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "grid_search.fit(X_train, y_train)  # 注意：SMOTE已集成在管道中\n",
    "\n",
    "# 评估函数\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'Train': {\n",
    "            'Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "            'Precision': precision_score(y_train, y_train_pred, average='weighted'),\n",
    "            'Recall': recall_score(y_train, y_train_pred, average='weighted'),\n",
    "            'F1': f1_score(y_train, y_train_pred, average='weighted')\n",
    "        },\n",
    "        'Test': {\n",
    "            'Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "            'Precision': precision_score(y_test, y_test_pred, average='weighted'),\n",
    "            'Recall': recall_score(y_test, y_test_pred, average='weighted'),\n",
    "            'F1': f1_score(y_test, y_test_pred, average='weighted')\n",
    "        }\n",
    "    }\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# 执行评估\n",
    "best_model = grid_search.best_estimator_\n",
    "metrics_df = evaluate_model(best_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 输出结果\n",
    "print(\"\\n=== 模型性能评估 ===\")\n",
    "print(metrics_df)\n",
    "print(\"\\n=== 最佳参数组合 ===\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\\n=== 测试集详细分类报告 ===\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))\n",
    "\n",
    "# 保存模型和结果\n",
    "joblib.dump(best_model, 'mlp_classifier.pkl')\n",
    "metrics_df.to_csv('mlp_model_metrics.csv', index=True)\n",
    "\n",
    "# 特征重要性分析（基于梯度）\n",
    "def calculate_feature_importance(model, preprocessor, X_sample):\n",
    "    \"\"\"通过反向传播计算特征重要性\"\"\"\n",
    "    # 获取预处理后的特征名称\n",
    "    selected_features = X.columns[\n",
    "        preprocessor.named_steps['variance_filter'].get_support()\n",
    "    ][preprocessor.named_steps['selector'].get_support()]\n",
    "    \n",
    "    # 获取第一层的权重\n",
    "    weights = model.named_steps['mlpclassifier'].coefs_[0]\n",
    "    \n",
    "    # 计算平均绝对权重\n",
    "    importance = np.mean(np.abs(weights), axis=1)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'feature': selected_features,\n",
    "        'importance': importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "# 计算特征重要性（示例）\n",
    "importance_df = calculate_feature_importance(\n",
    "    best_model, \n",
    "    preprocessor,\n",
    "    X_train[:10]  # 使用前10个样本计算\n",
    ")\n",
    "\n",
    "print(\"\\n=== Top 10重要特征 ===\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db0d90-41f2-4445-a04a-b7222b0e8867",
   "metadata": {},
   "source": [
    "## Tips.屏蔽日志信息\n",
    "\n",
    "通过设置verbose=0，屏蔽类似下列输出：\n",
    "- [CV] END mlpclassifier__activation=relu, mlpclassifier__alpha=0.0001, mlpclassifier__batch_size=32, mlpclassifier__dropout_rate=0.2, mlpclassifier__hidden_layer_sizes=(512,), mlpclassifier__learning_rate_init=0.001; total time= 7.8s\n",
    "- [CV] END mlpclassifier__activation=relu, mlpclassifier__alpha=0.0001, mlpclassifier__batch_size=32, mlpclassifier__dropout_rate=0.2, mlpclassifier__hidden_layer_sizes=(512,), mlpclassifier__learning_rate_init=0.001; total time= 7.1s\n",
    "\n",
    "但同时也屏蔽了：Fitting 3 folds for each of 32 candidates, totalling 96 fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b10e15b-f38f-46e0-8357-79bb741d0ce2",
   "metadata": {},
   "source": [
    "## 2.8 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1c54551-bdef-4cb4-a7b9-7ef92b22bab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "\n",
      "=== 模型性能评估 ===\n",
      "              Train      Test\n",
      "Accuracy   0.537313  0.402985\n",
      "Precision  0.740381  0.499207\n",
      "Recall     0.537313  0.402985\n",
      "F1         0.569041  0.425147\n",
      "\n",
      "=== 最佳参数组合 ===\n",
      "{'nb__var_smoothing': 1e-08, 'selector__k': 500}\n",
      "\n",
      "=== 测试集详细分类报告 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.42      0.48        19\n",
      "           1       0.46      0.30      0.36        20\n",
      "           2       0.19      0.56      0.28         9\n",
      "           3       0.62      0.42      0.50        19\n",
      "\n",
      "    accuracy                           0.40        67\n",
      "   macro avg       0.46      0.42      0.41        67\n",
      "weighted avg       0.50      0.40      0.43        67\n",
      "\n",
      "\n",
      "=== Top 10重要特征（F值）===\n",
      "             feature    f_score\n",
      "187  ENSG00000160932  29.373009\n",
      "118  ENSG00000133106  28.251515\n",
      "138  ENSG00000137965  27.890189\n",
      "137  ENSG00000137959  27.590781\n",
      "90   ENSG00000121236  26.197089\n",
      "33   ENSG00000089127  26.096280\n",
      "297  ENSG00000205837  25.943207\n",
      "117  ENSG00000132530  24.425000\n",
      "136  ENSG00000137628  23.298375\n",
      "374  ENSG00000238015  22.846449\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# 数据加载与预处理（保持原有流程）\n",
    "meta = pd.read_csv(\"./Data/GSE235508.meta.txt\", sep='\\t', dtype=str)\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)\n",
    "y = merged['group']\n",
    "\n",
    "# 标签编码\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 构建处理管道\n",
    "nb_pipeline = ImbPipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),          # 中位数填充\n",
    "    ('variance_filter', VarianceThreshold(threshold=0.1*(1-0.1))),  # 方差过滤\n",
    "    ('selector', SelectKBest(f_classif)),                   # 特征选择\n",
    "    ('scaler', StandardScaler()),                           # 标准化\n",
    "    ('smote', SMOTE(sampling_strategy='auto', k_neighbors=5)),  # SMOTE过采样\n",
    "    ('nb', GaussianNB())                                    # 朴素贝叶斯分类器\n",
    "])\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 超参数网格\n",
    "param_grid = {\n",
    "    'selector__k': [100, 500, 1000],                # 特征选择数量\n",
    "    'nb__var_smoothing': [1e-9, 1e-8, 1e-7]         # 方差平滑参数\n",
    "}\n",
    "\n",
    "# 评估指标\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision_weighted': make_scorer(precision_score, average='weighted'),\n",
    "    'recall_weighted': make_scorer(recall_score, average='weighted'),\n",
    "    'f1_weighted': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "# 配置网格搜索\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=nb_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1_weighted',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 执行评估\n",
    "best_model = grid_search.best_estimator_\n",
    "metrics_df = evaluate_model(best_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 输出结果\n",
    "print(\"\\n=== 模型性能评估 ===\")\n",
    "print(metrics_df)\n",
    "print(\"\\n=== 最佳参数组合 ===\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\\n=== 测试集详细分类报告 ===\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))\n",
    "\n",
    "# 特征重要性分析（基于F值）\n",
    "selector = best_model.named_steps['selector']\n",
    "variance_mask = best_model.named_steps['variance_filter'].get_support()\n",
    "selected_features = X.columns[variance_mask][selector.get_support()]\n",
    "\n",
    "f_scores = selector.scores_[selector.get_support()]\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': selected_features,\n",
    "    'f_score': f_scores\n",
    "}).sort_values('f_score', ascending=False)\n",
    "\n",
    "print(\"\\n=== Top 10重要特征（F值）===\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# 保存结果\n",
    "metrics_df.to_csv('nb_model_metrics.csv', index=True)\n",
    "importance_df.to_csv('nb_feature_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d89d2-0fba-45f3-975a-68e4b4c87017",
   "metadata": {},
   "source": [
    "## 2.9 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ab2b831-49f6-4b75-8511-7e2b2072dd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "\n",
      "=== 模型性能评估 ===\n",
      "              Train      Test\n",
      "Accuracy   0.861940  0.597015\n",
      "Precision  0.885929  0.689778\n",
      "Recall     0.861940  0.597015\n",
      "F1         0.864379  0.616060\n",
      "\n",
      "=== 最佳参数组合 ===\n",
      "{'knn__n_neighbors': 3, 'knn__p': 1, 'knn__weights': 'uniform', 'selector__k': 500}\n",
      "\n",
      "=== 测试集详细分类报告 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.59        19\n",
      "           1       0.91      0.50      0.65        20\n",
      "           2       0.30      0.67      0.41         9\n",
      "           3       0.72      0.68      0.70        19\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.64      0.61      0.59        67\n",
      "weighted avg       0.69      0.60      0.62        67\n",
      "\n",
      "\n",
      "=== Top 10重要特征（F值）===\n",
      "             feature    f_score\n",
      "187  ENSG00000160932  29.373009\n",
      "118  ENSG00000133106  28.251515\n",
      "138  ENSG00000137965  27.890189\n",
      "137  ENSG00000137959  27.590781\n",
      "90   ENSG00000121236  26.197089\n",
      "33   ENSG00000089127  26.096280\n",
      "297  ENSG00000205837  25.943207\n",
      "117  ENSG00000132530  24.425000\n",
      "136  ENSG00000137628  23.298375\n",
      "374  ENSG00000238015  22.846449\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# 数据加载与预处理（保持原有流程）\n",
    "meta = pd.read_csv(\"./Data/GSE235508.meta.txt\", sep='\\t', dtype=str)\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)\n",
    "y = merged['group']\n",
    "\n",
    "# 标签编码\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 构建处理管道\n",
    "knn_pipeline = ImbPipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),          # 中位数填充\n",
    "    ('variance_filter', VarianceThreshold(threshold=0.1*(1-0.1))),  # 方差过滤\n",
    "    ('selector', SelectKBest(f_classif)),                   # 特征选择\n",
    "    ('scaler', StandardScaler()),                           # 标准化（KNN必需）\n",
    "    ('smote', SMOTE(sampling_strategy='auto', k_neighbors=5)),  # SMOTE过采样\n",
    "    ('knn', KNeighborsClassifier())                         # KNN分类器\n",
    "])\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 超参数网格（优化后的参数范围）\n",
    "param_grid = {\n",
    "    'selector__k': [500, 1000],                     # 特征选择数量\n",
    "    'knn__n_neighbors': [3, 5, 7, 9],               # 近邻数（奇数避免平票）\n",
    "    'knn__weights': ['uniform', 'distance'],        # 权重类型\n",
    "    'knn__p': [1, 2]                                # 距离度量（1:曼哈顿，2:欧氏）\n",
    "}\n",
    "\n",
    "# 评估指标\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision_weighted': make_scorer(precision_score, average='weighted'),\n",
    "    'recall_weighted': make_scorer(recall_score, average='weighted'),\n",
    "    'f1_weighted': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "# 配置网格搜索\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knn_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1_weighted',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 执行评估\n",
    "best_model = grid_search.best_estimator_\n",
    "metrics_df = evaluate_model(best_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 输出结果\n",
    "print(\"\\n=== 模型性能评估 ===\")\n",
    "print(metrics_df)\n",
    "print(\"\\n=== 最佳参数组合 ===\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\\n=== 测试集详细分类报告 ===\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))\n",
    "\n",
    "# 特征重要性分析（基于F值）\n",
    "selector = best_model.named_steps['selector']\n",
    "variance_mask = best_model.named_steps['variance_filter'].get_support()\n",
    "selected_features = X.columns[variance_mask][selector.get_support()]\n",
    "\n",
    "f_scores = selector.scores_[selector.get_support()]\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': selected_features,\n",
    "    'f_score': f_scores\n",
    "}).sort_values('f_score', ascending=False)\n",
    "\n",
    "print(\"\\n=== Top 10重要特征（F值）===\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# 保存结果\n",
    "metrics_df.to_csv('knn_model_metrics.csv', index=True)\n",
    "importance_df.to_csv('knn_feature_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfab969-1f0e-435e-ba70-871b8049c5ba",
   "metadata": {},
   "source": [
    "## 2.10 集成特征选择方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25b88840-c9c2-4ff2-9ec7-c9724304116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "=== 模型性能评估 ===\n",
      "           Train      Test\n",
      "Accuracy     1.0  0.701493\n",
      "Precision    1.0  0.695801\n",
      "Recall       1.0  0.701493\n",
      "F1           1.0  0.694338\n",
      "\n",
      "=== 最佳参数组合 ===\n",
      "{'classifier__max_depth': None, 'classifier__n_estimators': 200, 'ensemble_selector__k': 300, 'smote__k_neighbors': 3}\n",
      "\n",
      "=== 测试集详细分类报告 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76        19\n",
      "           1       0.76      0.65      0.70        20\n",
      "           2       0.43      0.33      0.38         9\n",
      "           3       0.75      0.79      0.77        19\n",
      "\n",
      "    accuracy                           0.70        67\n",
      "   macro avg       0.66      0.65      0.65        67\n",
      "weighted avg       0.70      0.70      0.69        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "# 自定义集成特征选择器\n",
    "class EnsembleFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=500, voting_threshold=0.7):\n",
    "        self.k = k\n",
    "        self.voting_threshold = voting_threshold\n",
    "        self.selector1 = VarianceThreshold(threshold=0.1*(1-0.1))\n",
    "        self.selector2 = SelectKBest(f_classif, k=k)\n",
    "        self.selector3 = SelectFromModel(\n",
    "            RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "            threshold=\"median\"\n",
    "        )\n",
    "        self.selected_features_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # 第一层选择：方差过滤\n",
    "        self.selector1.fit(X, y)\n",
    "        var_mask = self.selector1.get_support()\n",
    "        \n",
    "        # 第二层选择：ANOVA F值\n",
    "        self.selector2.fit(X[:, var_mask], y)\n",
    "        fvalue_mask = self.selector2.get_support()\n",
    "        \n",
    "        # 第三层选择：随机森林重要性\n",
    "        self.selector3.fit(X[:, var_mask][:, fvalue_mask], y)\n",
    "        model_mask = self.selector3.get_support()\n",
    "        \n",
    "        # 组合选择结果\n",
    "        final_mask = var_mask.copy()\n",
    "        final_mask[var_mask] = fvalue_mask\n",
    "        final_mask[final_mask] = model_mask\n",
    "        \n",
    "        self.selected_features_ = final_mask\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self, 'selected_features_')\n",
    "        return X[:, self.selected_features_]\n",
    "\n",
    "# 数据加载与预处理（保持原有流程）\n",
    "meta = pd.read_csv(\"./Data/GSE235508.meta.txt\", sep='\\t', dtype=str)\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)\n",
    "y = merged['group']\n",
    "\n",
    "# 标签编码\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 构建处理管道\n",
    "ensemble_pipeline = ImbPipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),          # 中位数填充\n",
    "    ('ensemble_selector', EnsembleFeatureSelector()),       # 集成特征选择\n",
    "    ('scaler', StandardScaler()),                           # 标准化\n",
    "    ('smote', SMOTE(sampling_strategy='auto', k_neighbors=5)),  # SMOTE过采样\n",
    "    ('classifier', RandomForestClassifier())                # 基础分类器\n",
    "])\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 超参数网格\n",
    "param_grid = {\n",
    "    'ensemble_selector__k': [300, 500, 800],        # 特征选择数量\n",
    "    'classifier__n_estimators': [100, 200],         # 随机森林参数\n",
    "    'classifier__max_depth': [None, 10],\n",
    "    'smote__k_neighbors': [3, 5]\n",
    "}\n",
    "\n",
    "# 评估指标\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision_weighted': make_scorer(precision_score, average='weighted'),\n",
    "    'recall_weighted': make_scorer(recall_score, average='weighted'),\n",
    "    'f1_weighted': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "# 配置网格搜索\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ensemble_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1_weighted',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 执行评估\n",
    "best_model = grid_search.best_estimator_\n",
    "metrics_df = evaluate_model(best_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 输出结果\n",
    "print(\"\\n=== 模型性能评估 ===\")\n",
    "print(metrics_df)\n",
    "print(\"\\n=== 最佳参数组合 ===\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\\n=== 测试集详细分类报告 ===\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))\n",
    "\n",
    "# 保存结果\n",
    "metrics_df.to_csv('ensemble_feature_model_metrics.csv', index=True)\n",
    "importance_df.to_csv('ensemble_feature_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9180fe9-35f4-428f-a51c-d25599cb9307",
   "metadata": {},
   "source": [
    "# 3.Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b5c497e-beec-4d53-bf49-7d14d8d4cd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 回归模型性能比较 ===\n",
      "                   Model       MSE       MAE        R2           Best Params\n",
      "0      Linear Regression  1.962464  0.972609 -2.706266                    {}\n",
      "1  Polynomial Regression  0.430455  0.537993  0.187053   {'poly__degree': 2}\n",
      "2    Quantile Regression  0.331746  0.470524  0.373471  {'reg__alpha': 0.25}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, QuantileRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 数据加载与预处理\n",
    "def load_data():\n",
    "    # 加载元数据\n",
    "    meta = pd.read_csv(\"./Data/GSE235508.meta.txt\", sep='\\t', quotechar='\"', dtype=str)\n",
    "    meta = meta[['geo_accession', 'das28:ch1', 'library size:ch1']]\n",
    "    meta = meta[meta['das28:ch1'] != 'NA'].dropna()\n",
    "    \n",
    "    # 加载表达数据\n",
    "    expr = pd.read_csv(\"./Data/GSE235508_mRNA_counts.txt\", sep='\\t', comment='!', index_col=0, encoding='utf-8').T\n",
    "    expr = expr.merge(meta, left_index=True, right_on='geo_accession')\n",
    "    \n",
    "    # 准备数据\n",
    "    X = expr.drop(['geo_accession', 'das28:ch1', 'library size:ch1'], axis=1).astype(float)\n",
    "    y = expr['das28:ch1'].astype(float)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# 数据预处理管道\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('selector', SelectKBest(f_regression, k=500)),\n",
    "    ('pca', PCA(n_components=0.95))\n",
    "])\n",
    "\n",
    "# 加载数据\n",
    "X, y = load_data()\n",
    "X_processed = preprocessor.fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 模型定义\n",
    "models = {\n",
    "    \"Linear Regression\": Pipeline([\n",
    "        ('reg', LinearRegression())\n",
    "    ]),\n",
    "    \"Polynomial Regression\": Pipeline([\n",
    "        ('poly', PolynomialFeatures()),\n",
    "        ('reg', LinearRegression())\n",
    "    ]),\n",
    "    \"Quantile Regression\": Pipeline([\n",
    "        ('reg', QuantileRegressor(alpha=0.5, solver='highs'))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 超参数网格\n",
    "params = {\n",
    "    'Polynomial Regression': {'poly__degree': [2, 3]},\n",
    "    'Quantile Regression': {'reg__alpha': [0.25, 0.5, 0.75]}\n",
    "}\n",
    "\n",
    "# 训练与评估\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    grid = GridSearchCV(model, params.get(name, {}), cv=5, scoring='neg_mean_squared_error')\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'Model': name,\n",
    "        'Best Params': grid.best_params_,\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred)\n",
    "    }\n",
    "    results.append(metrics)\n",
    "\n",
    "# 结果展示\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"=== 回归模型性能比较 ===\")\n",
    "print(results_df[['Model', 'MSE', 'MAE', 'R2', 'Best Params']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2300df94-e299-4bb7-a2a4-2ed635e1fdfd",
   "metadata": {},
   "source": [
    "# 4. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187ebb74-8d5f-4c0b-a169-9ad1a3e0634d",
   "metadata": {},
   "source": [
    "## 4.1 分类模型对比"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bf189-db17-46ee-8843-ddfa2fe71e17",
   "metadata": {},
   "source": [
    "在GSE235508转录组数据集（自身免疫疾病状态多分类）的实验中，不同算法表现出显著性能差异：\n",
    "\n",
    "**最佳表现模型：**\n",
    "1. **神经网络（MLP）**  \n",
    "   - 测试准确率：91.04% | F1值：0.91  \n",
    "   - 优势：通过隐藏层捕捉复杂非线性模式，dropout正则化（0.5）有效防止过拟合  \n",
    "   - 局限：需精细调节学习率（0.0005）和网络结构（256-128隐藏单元）\n",
    "\n",
    "2. **支持向量机（SVM）**  \n",
    "   - 测试准确率：86.57% | F1值：0.86  \n",
    "   - 最优配置：RBF核函数（C=10，gamma='scale'）  \n",
    "   - 特点：通过核技巧处理高维数据，最大化分类间隔\n",
    "\n",
    "3. **Lasso回归**  \n",
    "   - 测试准确率：89.55% | F1值：0.91  \n",
    "   - 关键特性：L1正则化筛选23%基因（稀疏解），提升可解释性\n",
    "\n",
    "**欠佳模型：**  \n",
    "| 模型                | 测试准确率 | 主要局限                     |\n",
    "|---------------------|------------|-----------------------------|\n",
    "| 随机森林            | 37.31%     | 严重过拟合（训练集准确率77%）|\n",
    "| K近邻               | 59.70%     | 受维度灾难影响显著          |\n",
    "| 朴素贝叶斯          | 40.30%     | 违背特征独立性假设          |\n",
    "\n",
    "**TIPS：**  \n",
    "- **维度影响：** 树模型（随机森林、XGBoost）因高维小样本特性（6万基因/335样本）泛化能力差，而正则化线性模型（Lasso、弹性网络）稳定性更佳  \n",
    "- **类别不平衡：** SMOTE过采样使少数类召回率整体提升15-20%，对SVM和MLP效果最显著  \n",
    "- **特征选择：** 集成特征选择方法（ANOVA F检验+随机森林）相比单一方法F1值提升8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9e40e7-a186-47d2-b7a2-ee8bf4e0cc7b",
   "metadata": {},
   "source": [
    "## 4.2 回归模型对比"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13729bee-1ddc-46c3-9bec-a8e39caad830",
   "metadata": {},
   "source": [
    "在DAS28疾病活动度预测任务中，三种回归方法表现如下：\n",
    "\n",
    "| 模型                  | 均方误差 | 平均绝对误差 | R²值   | 最优参数                 |\n",
    "|-----------------------|----------|--------------|--------|--------------------------|\n",
    "| 分位数回归            | 0.332    | 0.471        | 0.373  | α=0.25，solver='highs'   |\n",
    "| 多项式回归            | 0.430    | 0.538        | 0.187  | degree=2                 |\n",
    "| 线性回归              | 1.962    | 0.973        | -2.706 | 无                       |\n",
    "\n",
    "**TIPS：**  \n",
    "1. **分位数回归** 通过处理基因表达数据的非正态误差分布，取得最佳预测效果（R²=0.373）  \n",
    "2. **多项式特征**（二次项）虽能捕捉部分非线性关系，但增加模型复杂度  \n",
    "3. **线性回归** 完全失效（负R²值），表明模型与生物学关系严重不匹配"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fda988-ef64-4806-8391-cc605375ee72",
   "metadata": {},
   "source": [
    "## 4.3 后续改进方向"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6749df-2c3d-476b-bebf-4904a8090d92",
   "metadata": {},
   "source": [
    "结合通路分析（如GO富集），从而在生物可解释性、维度复杂性取得更好的平衡。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
