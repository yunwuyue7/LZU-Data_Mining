{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e70e76-de0b-4a1a-932c-262671f7e06c",
   "metadata": {},
   "source": [
    "# Data Mining Project3: Classification on Given Dataset \n",
    "- e-mail: niejy20@lzu.edu.cn\n",
    "- data：May 17th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e53319-b0ab-4749-9ef6-45e9c90d263a",
   "metadata": {},
   "source": [
    "## 1.1 数据集简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0ce53-b394-4771-9077-1a7b4d75098c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### GSE235508 转录组数据集\n",
    "\n",
    "- **数据来源**：来自类风湿关节炎（RA）、系统性红斑狼疮（SLE）患者及健康孕妇的血液转录组数据，旨在分析妊娠期免疫调节的基因表达差异。\n",
    "- **分类任务**：将样本分为不同组别（如 `HEALTHY`、`SPRA`、`SLE`），属于多分类问题（具体类别需根据 `samplegroup:ch1` 的取值确定）。\n",
    "- **数据规模**：包含 **335 个样本**，每个样本有 **60,218 个基因表达特征**（CPM 值），属于典型的高维小样本数据。\n",
    "- **特征特点**：特征为基因表达量，需进行标准化处理（如 log 转换），且存在大量零值或低方差基因，需进行特征筛选。\n",
    "\n",
    "---\n",
    "\n",
    "### 数据集对比\n",
    "- 在第一次作业中，我使用了数据挖掘领域较为经典的数据集：Breast Cancer Wisconsin，与本次作业的数据集同样应用于医学领域，这两个数据集的区别如下：\n",
    "\n",
    "| 特征                  | GSE235508 转录组数据集       | Breast Cancer Wisconsin 数据集 |\n",
    "|-----------------------|------------------------------|---------------------------------|\n",
    "| **数据量**            | 335 个样本                   | 569 个样本                      |\n",
    "| **特征数量**          | 60,218 个基因表达特征        | 30 个形态学特征                 |\n",
    "| **应用领域**          | 自身免疫疾病研究             | 乳腺癌医学诊断                  |\n",
    "| **分类任务**          | 多分类（疾病状态分组）       | 二分类（良性 vs 恶性）          \n",
    "| **数据挑战**          | 高维度、小样本、特征稀疏     | 小样本、特征可解释性高          |\n",
    "| **典型预处理方法**    | 标准化、特征选择、降维       | 标准化、特征相关性分析          |\n",
    "\n",
    "---\n",
    "\n",
    "### 对比分析\n",
    "\n",
    "1. **数据维度差异**  \n",
    "   - GSE235508 的特征数量（60k+）远超 Breast Cancer（30），需采用 **PCA、t-SNE 或 LASSO 特征选择** 避免维度灾难。\n",
    "   - 与 Breast Cancer 数据集相比，GSE235508 的样本量更小，但特征维度更高，容易导致模型过拟合，需结合正则化或集成学习。\n",
    "\n",
    "2. **领域特异性**  \n",
    "   - **医学转录组数据** 的基因表达特征具有生物学意义，但需结合通路分析（如 GSEA）增强可解释性。\n",
    "   - 不同于 MiniBooNE 的物理信号，基因表达数据通常需 **log 转换** 和 **批次效应校正**。\n",
    "\n",
    "3. **实际应用建议**  \n",
    "   - 对 GSE235508 优先使用 **随机森林、SVM（RBF 核）** 或 **XGBoost**，配合交叉验证。\n",
    "   - 若需深度学习，可尝试 **自编码器降维** 或 **注意力机制** 处理高维稀疏特征。\n",
    "\n",
    "---\n",
    "\n",
    "通过对比可见，GSE235508 的 **高维小样本特性** 使其在模型选择上更接近基因组学研究的典型挑战，需综合特征工程与正则化策略平衡过拟合风险。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fa1d59-5f54-492b-b909-4869e2aef936",
   "metadata": {},
   "source": [
    "## 1.2 分类算法简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa4ae3-9001-4ed6-987e-ca0c71c4355b",
   "metadata": {},
   "source": [
    "分类算法可以根据不同的特点和学习方式来进行区分。以下是4种常见的分类方式："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c395d1-1c07-441b-b30a-0cd9519c89f3",
   "metadata": {},
   "source": [
    "### 一、基于学习方式\n",
    "\n",
    "| 分类依据 | 常见算法 | 特点 |\n",
    "| --- | --- | --- |\n",
    "| 监督学习 | 决策树、逻辑回归、支持向量机、朴素贝叶斯等 | 从带标签的数据中学习，映射函数将输入数据映射到已知的输出标签 |\n",
    "| 无监督学习 | k-均值聚类、层次聚类、高斯混合模型等 | 不依赖标记的训练数据，可以对数据进行聚类或降维等操作 |\n",
    "| 半监督学习 | 自训练算法、多视图训练算法等 | 结合少量有标签数据和大量无标签数据进行学习，通过无标签数据来提高模型的性能 |\n",
    "| 强化学习 | Q-learning、策略梯度方法等 | 通过与环境的交互来学习最优的行为策略，以最大化累积奖励 |\n",
    "\n",
    "### 二、基于模型复杂度\n",
    "\n",
    "| 分类依据 | 常见算法 | 特点 |\n",
    "| --- | --- | --- |\n",
    "| 简单模型 | 逻辑回归、决策树桩等 | 结构简单，训练和预测速度快，易于理解和解释，适用于数据规模较小或特征较少的情况 |\n",
    "| 集成模型 | 随机森林、AdaBoost、梯度提升树、XGBoost等 | 组合多个弱学习器以构建强大的模型，能够提高模型的准确性和泛化能力，但模型复杂度较高，训练和预测时间较长 |\n",
    "\n",
    "### 三、基于数据特点\n",
    "\n",
    "| 分类依据 | 常见算法 | 特点 |\n",
    "| --- | --- | --- |\n",
    "| 线性可分数据 | 逻辑回归、线性支持向量机等 | 适用于数据在特征空间中线性可分的情况，通过寻找一个线性决策边界来区分不同类别的样本 |\n",
    "| 非线性数据 | 决策树、支持向量机（非线性核函数）、神经网络等 | 适用于数据在特征空间中非线性可分的情况，能够学习复杂的非线性决策边界 |\n",
    "\n",
    "### 四、基于模型可解释性\n",
    "\n",
    "| 分类依据 | 常见算法 | 特点 |\n",
    "| --- | --- | --- |\n",
    "| 可解释模型 | 决策树、逻辑回归等 | 模型的决策过程易于理解和解释，能够提供直观的特征重要性和决策规则 |\n",
    "| 黑盒模型 | 神经网络、梯度提升树等 | 模型的内部结构和决策过程较为复杂，可解释性差，但通常具有较高的预测性能|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1620f50e-f298-44c0-987d-2206590c3de4",
   "metadata": {},
   "source": [
    "在本次project中，共使用了10种用于分类任务的算法，这些算法的简介如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22596f5f-b9ef-4019-9f0c-bf55dd2777a9",
   "metadata": {},
   "source": [
    "1. Logistic Regression：基于逻辑函数（Sigmoid函数）建模，输出概率值，能够提供可解释的特征权重。\n",
    "\n",
    "2. k-NN（k-近邻算法）：懒惰学习（lazy learning），在预测阶段才进行计算，不显式训练模型。\n",
    "\n",
    "3. Decision Tree：易于理解和解释，能够处理非线性关系，无需数据归一化。\n",
    "\n",
    "4. Decision Stump：极其简单，计算效率高，但表达能力有限。\n",
    "\n",
    "5. Random Forest：通过随机抽样和特征选择来降低过拟合风险，提高模型的泛化能力。\n",
    "\n",
    "6. AdaBoost（自适应提升算法）：强调对分类错误的样本给予更高的权重，使得后续学习器更关注这些样本。\n",
    "\n",
    "7. XGBoost（极端梯度提升）：高效、可扩展，支持自动处理缺失值，提供多种正则化选项。\n",
    "\n",
    "8. LDA（Linear Discriminant Analysis）：假设数据服从高斯分布，计算类内和类间散度矩阵。\n",
    "\n",
    "9. Naive Bayes：计算概率模型，对缺失数据具有鲁棒性，无需复杂的训练过程。\n",
    "\n",
    "10. Maximal Entropy Model：在给定约束条件下选择最不确定的分布，避免过度拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196237ae-f3fb-42a5-a0e0-05ded1e6dcf6",
   "metadata": {},
   "source": [
    "## 1.3 格式说明"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974803cb-249a-4ec9-a7cf-2b4273f77c33",
   "metadata": {},
   "source": [
    "### this is format description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b67639c-21e8-4f73-b8e7-d78be096e8b3",
   "metadata": {},
   "source": [
    "## 2.1 RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "31132894-cea8-486b-9a76-f9c9d0704039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (335, 60220)\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Parameters: {'rf__bootstrap': True, 'rf__max_depth': 10, 'rf__max_features': 0.5, 'rf__min_samples_split': 2, 'rf__n_estimators': 50}\n",
      "Train F1: 0.787\n",
      "Test F1: 0.418\n",
      "Top 10重要基因:\n",
      "                gene  importance\n",
      "207  ENSG00000165887    0.233116\n",
      "436  ENSG00000256128    0.200232\n",
      "76   ENSG00000119906    0.157042\n",
      "128  ENSG00000137877    0.152141\n",
      "109  ENSG00000134283    0.142218\n",
      "77   ENSG00000119913    0.140578\n",
      "239  ENSG00000172971    0.116268\n",
      "103  ENSG00000132182    0.109554\n",
      "261  ENSG00000181092    0.089148\n",
      "275  ENSG00000185551    0.085321\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "\n",
    "# 加载元数据（使用geo_accession）\n",
    "meta = pd.read_csv(\n",
    "    \"./Data/GSE235508.meta.txt\",\n",
    "    sep='\\t',\n",
    "    quotechar='\"',\n",
    "    encoding='utf-8',\n",
    "    dtype=str\n",
    ")\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "# 加载表达数据\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "# 合并数据\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "print(f\"Merged shape: {merged.shape}\")  # 应输出(335, 60220)\n",
    "\n",
    "# 特征矩阵和目标变量\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)  # 确保数值类型\n",
    "y = merged['group']\n",
    "\n",
    "# 标签编码\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 数据预处理管道\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # 中位数填充缺失值\n",
    "    ('variance_filter', VarianceThreshold(threshold=0.1*(1-0.1))),  # 移除低方差特征\n",
    "    ('selector', SelectKBest(f_classif, k=500)),  # 选择top k个差异基因\n",
    "    ('pca', PCA(n_components=0.95)),  # 保留95%方差的主成分\n",
    "])\n",
    "\n",
    "# 划分训练测试集（先预处理再划分）\n",
    "X_preprocessed = preprocessor.fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 处理类别不平衡（仅在训练集应用SMOTE）\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=10)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 构建随机森林模型管道\n",
    "rf_pipeline = Pipeline([\n",
    "    ('rf', RandomForestClassifier(max_depth=10, min_samples_leaf=5))\n",
    "])\n",
    "\n",
    "# 超参数网格搜索\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__max_depth': [None, 10, 20],\n",
    "    'rf__min_samples_split': [2, 5],\n",
    "    'rf__max_features': ['sqrt', 0.5],\n",
    "    'rf__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',  # 使用加权F1-score\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 训练与调优\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 评估最佳模型\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Train F1: {best_model.score(X_train_res, y_train_res):.3f}\")\n",
    "print(f\"Test F1: {best_model.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# 保存最佳模型\n",
    "joblib.dump(best_model, 'best_rf_model.pkl')\n",
    "\n",
    "# 特征重要性分析\n",
    "# 获取特征选择后的基因索引\n",
    "selected_idx = preprocessor.named_steps['selector'].get_support(indices=True)\n",
    "feature_names = X.columns[selected_idx]\n",
    "\n",
    "# 获取PCA前的特征重要性\n",
    "importances = best_model.named_steps['rf'].feature_importances_\n",
    "pca_components = preprocessor.named_steps['pca'].components_\n",
    "\n",
    "# 映射回原始特征空间\n",
    "raw_importances = np.abs(pca_components.T @ importances).flatten()\n",
    "\n",
    "# 创建重要性DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'gene': feature_names,\n",
    "    'importance': raw_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10重要基因:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa42bb-0d87-449f-b901-4071296b1ea1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tips.随机森林参数调整\n",
    "第一遍结果F1 score为0.448，k_neighbors（SMOTE参数）取3，SelectKBest参数取500。\n",
    "\n",
    "调整后：F1=0.448"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1f659-6af4-425a-a1aa-9bc2d3b4362c",
   "metadata": {},
   "source": [
    "## 2.2 SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77921e15-0585-432e-bfbc-8a4b77a76c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (335, 60220)\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Best Parameters: {'svc__C': 1, 'svc__class_weight': None, 'svc__gamma': 'scale', 'svc__kernel': 'linear'}\n",
      "Train F1: 1.000\n",
      "Test F1: 0.836\n",
      "Top 10重要基因（线性核）:\n",
      "                gene  importance\n",
      "499  ENSG00000277051    0.261370\n",
      "176  ENSG00000156256    0.133494\n",
      "297  ENSG00000196504    0.131095\n",
      "452  ENSG00000261609    0.128555\n",
      "182  ENSG00000158458    0.124338\n",
      "364  ENSG00000228073    0.115773\n",
      "343  ENSG00000211801    0.110355\n",
      "471  ENSG00000266412    0.108808\n",
      "211  ENSG00000166948    0.104328\n",
      "193  ENSG00000163482    0.104199\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "\n",
    "# 数据加载与合并（与原始代码一致）\n",
    "meta = pd.read_csv(\n",
    "    \"./Data/GSE235508.meta.txt\",\n",
    "    sep='\\t',\n",
    "    quotechar='\"',\n",
    "    encoding='utf-8',\n",
    "    dtype=str\n",
    ")\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "print(f\"Merged shape: {merged.shape}\")\n",
    "\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)\n",
    "y = merged['group']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 增加标准化步骤\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('variance_filter', VarianceThreshold(threshold=0.1*(1-0.1))),\n",
    "    ('selector', SelectKBest(f_classif, k=500)),\n",
    "    ('scaler', StandardScaler()),  # SVC需要特征标准化\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "])\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=10)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "svc_pipeline = Pipeline([\n",
    "    ('svc', SVC(probability=True, decision_function_shape='ovr'))  # 启用概率估计\n",
    "])\n",
    "\n",
    "# 调整SVC参数\n",
    "param_grid = {\n",
    "    'svc__C': [0.1, 1, 10],  # 正则化参数\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'svc__gamma': ['scale', 'auto'],  # 仅对非线性核有效\n",
    "    'svc__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svc_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3,  # 减少交叉验证折数以节省时间\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Train F1: {best_model.score(X_train_res, y_train_res):.3f}\")\n",
    "print(f\"Test F1: {best_model.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# 保存最佳模型\n",
    "joblib.dump(best_model, 'best_svc_model.pkl')\n",
    "\n",
    "# 特征重要性分析（仅适用于线性核）\n",
    "if best_model.named_steps['svc'].kernel == 'linear':\n",
    "    coef = best_model.named_steps['svc'].coef_\n",
    "    pca_components = preprocessor.named_steps['pca'].components_\n",
    "    \n",
    "    raw_importances = np.abs(pca_components.T @ coef.mean(axis=0)).flatten()\n",
    "    \n",
    "    selected_idx = preprocessor.named_steps['selector'].get_support(indices=True)\n",
    "    feature_names = X.columns[selected_idx]\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'gene': feature_names,\n",
    "        'importance': raw_importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"Top 10重要基因（线性核）:\")\n",
    "    print(importance_df.head(10))\n",
    "else:\n",
    "    print(\"特征重要性分析仅适用于线性核\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af0041-684b-493b-aa96-9f1f4a77e311",
   "metadata": {},
   "source": [
    "## 2.3 Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44503ada-dfac-4b36-9abb-8bc650e57d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (335, 60220)\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best Parameters: {'lr__C': 100.0}\n",
      "Train F1: 0.997\n",
      "Test F1: 0.910\n",
      "Top 10重要基因:\n",
      "                gene  importance\n",
      "347  ENSG00000216859    0.001634\n",
      "370  ENSG00000229395    0.001155\n",
      "297  ENSG00000196504    0.001147\n",
      "302  ENSG00000197483    0.001126\n",
      "354  ENSG00000222419    0.001118\n",
      "493  ENSG00000274282    0.001038\n",
      "45   ENSG00000101222    0.001027\n",
      "470  ENSG00000265980    0.000989\n",
      "265  ENSG00000182351    0.000934\n",
      "6    ENSG00000007350    0.000912\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "\n",
    "# 数据加载\n",
    "meta = pd.read_csv(\n",
    "    \"./Data/GSE235508.meta.txt\",\n",
    "    sep='\\t',\n",
    "    quotechar='\"',\n",
    "    encoding='utf-8',\n",
    "    dtype=str\n",
    ")\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "print(f\"Merged shape: {merged.shape}\")\n",
    "\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)\n",
    "y = merged['group']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 数据预处理管道\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('variance_filter', VarianceThreshold(threshold=0.1*(1-0.1))),\n",
    "    ('selector', SelectKBest(f_classif, k=500)),\n",
    "    ('scaler', StandardScaler()),  # 必须标准化\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "])\n",
    "\n",
    "# 划分训练测试集、处理类别不平衡\n",
    "X_preprocessed = preprocessor.fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=10)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 构建Lasso逻辑回归模型\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('lr', LogisticRegression(\n",
    "        penalty='l1',  # L1正则化\n",
    "        solver='saga',  # 唯一支持L1+多分类的求解器\n",
    "        max_iter=10000,  \n",
    "        tol=5e-4\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'lr__C': np.logspace(-3, 2, 6),  # 正则化强度：0.001到100\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lasso_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 训练、调优、选择最佳超参数\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Train F1: {best_model.score(X_train_res, y_train_res):.3f}\")\n",
    "print(f\"Test F1: {best_model.score(X_test, y_test):.3f}\")\n",
    "\n",
    "joblib.dump(best_model, 'best_lasso_lr_model.pkl')\n",
    "\n",
    "coef_matrix = best_model.named_steps['lr'].coef_\n",
    "pca_components = preprocessor.named_steps['pca'].components_\n",
    "\n",
    "# 映射回原始特征空间（对各类别系数取平均）\n",
    "raw_importances = np.abs(pca_components.T @ coef_matrix.mean(axis=0)).flatten()\n",
    "\n",
    "selected_idx = preprocessor.named_steps['selector'].get_support(indices=True)\n",
    "feature_names = X.columns[selected_idx]\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'gene': feature_names,\n",
    "    'importance': raw_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10重要基因:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed99fa3c-ce76-4e5d-bd47-304236da9d83",
   "metadata": {},
   "source": [
    "## Tips.收敛警告\n",
    "构建Lasso回归模型时，下列两个参数设置不合适可能会导致收敛警告：\n",
    "\n",
    "- max_iter=1000, \n",
    "- tol=1e-4\n",
    "\n",
    "C:\\Users\\20187\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
    "warnings.warn(\n",
    "\n",
    "原因：1.迭代次数不足（max_iter 设置过小）、2.敛容差过严（tol 设置过小）\n",
    "\n",
    "将迭代次数增加至10000、收敛阈值减半，警告消失。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b77f85-ddf0-4dcf-be5a-4b467e878419",
   "metadata": {},
   "source": [
    "## 2.4 XGBoost/LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6245855-5ad3-4aaf-b06d-7d36db82ed8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (335, 60220)\n",
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "[0]\tvalidation_0-mlogloss:1.38309\n",
      "[1]\tvalidation_0-mlogloss:1.38040\n",
      "[2]\tvalidation_0-mlogloss:1.37819\n",
      "[3]\tvalidation_0-mlogloss:1.37580\n",
      "[4]\tvalidation_0-mlogloss:1.37319\n",
      "[5]\tvalidation_0-mlogloss:1.37179\n",
      "[6]\tvalidation_0-mlogloss:1.36978\n",
      "[7]\tvalidation_0-mlogloss:1.36784\n",
      "[8]\tvalidation_0-mlogloss:1.36600\n",
      "[9]\tvalidation_0-mlogloss:1.36329\n",
      "[10]\tvalidation_0-mlogloss:1.36190\n",
      "[11]\tvalidation_0-mlogloss:1.35988\n",
      "[12]\tvalidation_0-mlogloss:1.35750\n",
      "[13]\tvalidation_0-mlogloss:1.35589\n",
      "[14]\tvalidation_0-mlogloss:1.35342\n",
      "[15]\tvalidation_0-mlogloss:1.35220\n",
      "[16]\tvalidation_0-mlogloss:1.35057\n",
      "[17]\tvalidation_0-mlogloss:1.34893\n",
      "[18]\tvalidation_0-mlogloss:1.34713\n",
      "[19]\tvalidation_0-mlogloss:1.34577\n",
      "[20]\tvalidation_0-mlogloss:1.34402\n",
      "[21]\tvalidation_0-mlogloss:1.34178\n",
      "[22]\tvalidation_0-mlogloss:1.34013\n",
      "[23]\tvalidation_0-mlogloss:1.33881\n",
      "[24]\tvalidation_0-mlogloss:1.33718\n",
      "[25]\tvalidation_0-mlogloss:1.33487\n",
      "[26]\tvalidation_0-mlogloss:1.33345\n",
      "[27]\tvalidation_0-mlogloss:1.33168\n",
      "[28]\tvalidation_0-mlogloss:1.33014\n",
      "[29]\tvalidation_0-mlogloss:1.32932\n",
      "[30]\tvalidation_0-mlogloss:1.32790\n",
      "[31]\tvalidation_0-mlogloss:1.32620\n",
      "[32]\tvalidation_0-mlogloss:1.32411\n",
      "[33]\tvalidation_0-mlogloss:1.32317\n",
      "[34]\tvalidation_0-mlogloss:1.32288\n",
      "[35]\tvalidation_0-mlogloss:1.32212\n",
      "[36]\tvalidation_0-mlogloss:1.32068\n",
      "[37]\tvalidation_0-mlogloss:1.31949\n",
      "[38]\tvalidation_0-mlogloss:1.31853\n",
      "[39]\tvalidation_0-mlogloss:1.31760\n",
      "[40]\tvalidation_0-mlogloss:1.31712\n",
      "[41]\tvalidation_0-mlogloss:1.31632\n",
      "[42]\tvalidation_0-mlogloss:1.31482\n",
      "[43]\tvalidation_0-mlogloss:1.31411\n",
      "[44]\tvalidation_0-mlogloss:1.31329\n",
      "[45]\tvalidation_0-mlogloss:1.31276\n",
      "[46]\tvalidation_0-mlogloss:1.31173\n",
      "[47]\tvalidation_0-mlogloss:1.31078\n",
      "[48]\tvalidation_0-mlogloss:1.30956\n",
      "[49]\tvalidation_0-mlogloss:1.30914\n",
      "[50]\tvalidation_0-mlogloss:1.30840\n",
      "[51]\tvalidation_0-mlogloss:1.30797\n",
      "[52]\tvalidation_0-mlogloss:1.30731\n",
      "[53]\tvalidation_0-mlogloss:1.30640\n",
      "[54]\tvalidation_0-mlogloss:1.30610\n",
      "[55]\tvalidation_0-mlogloss:1.30548\n",
      "[56]\tvalidation_0-mlogloss:1.30485\n",
      "[57]\tvalidation_0-mlogloss:1.30333\n",
      "[58]\tvalidation_0-mlogloss:1.30328\n",
      "[59]\tvalidation_0-mlogloss:1.30259\n",
      "[60]\tvalidation_0-mlogloss:1.30220\n",
      "[61]\tvalidation_0-mlogloss:1.30141\n",
      "[62]\tvalidation_0-mlogloss:1.30070\n",
      "[63]\tvalidation_0-mlogloss:1.29914\n",
      "[64]\tvalidation_0-mlogloss:1.29928\n",
      "[65]\tvalidation_0-mlogloss:1.29839\n",
      "[66]\tvalidation_0-mlogloss:1.29784\n",
      "[67]\tvalidation_0-mlogloss:1.29731\n",
      "[68]\tvalidation_0-mlogloss:1.29640\n",
      "[69]\tvalidation_0-mlogloss:1.29605\n",
      "[70]\tvalidation_0-mlogloss:1.29521\n",
      "[71]\tvalidation_0-mlogloss:1.29446\n",
      "[72]\tvalidation_0-mlogloss:1.29443\n",
      "[73]\tvalidation_0-mlogloss:1.29348\n",
      "[74]\tvalidation_0-mlogloss:1.29328\n",
      "[75]\tvalidation_0-mlogloss:1.29240\n",
      "[76]\tvalidation_0-mlogloss:1.29177\n",
      "[77]\tvalidation_0-mlogloss:1.29054\n",
      "[78]\tvalidation_0-mlogloss:1.29024\n",
      "[79]\tvalidation_0-mlogloss:1.28981\n",
      "[80]\tvalidation_0-mlogloss:1.28916\n",
      "[81]\tvalidation_0-mlogloss:1.28890\n",
      "[82]\tvalidation_0-mlogloss:1.28862\n",
      "[83]\tvalidation_0-mlogloss:1.28800\n",
      "[84]\tvalidation_0-mlogloss:1.28761\n",
      "[85]\tvalidation_0-mlogloss:1.28800\n",
      "[86]\tvalidation_0-mlogloss:1.28823\n",
      "[87]\tvalidation_0-mlogloss:1.28822\n",
      "[88]\tvalidation_0-mlogloss:1.28809\n",
      "[89]\tvalidation_0-mlogloss:1.28788\n",
      "[90]\tvalidation_0-mlogloss:1.28734\n",
      "[91]\tvalidation_0-mlogloss:1.28687\n",
      "[92]\tvalidation_0-mlogloss:1.28624\n",
      "[93]\tvalidation_0-mlogloss:1.28631\n",
      "[94]\tvalidation_0-mlogloss:1.28577\n",
      "[95]\tvalidation_0-mlogloss:1.28531\n",
      "[96]\tvalidation_0-mlogloss:1.28442\n",
      "[97]\tvalidation_0-mlogloss:1.28374\n",
      "[98]\tvalidation_0-mlogloss:1.28307\n",
      "[99]\tvalidation_0-mlogloss:1.28288\n",
      "Best Parameters: {'xgb__colsample_bytree': 1.0, 'xgb__gamma': 0.1, 'xgb__learning_rate': 0.01, 'xgb__max_depth': 5, 'xgb__n_estimators': 100, 'xgb__subsample': 0.8}\n",
      "Train F1: 0.799\n",
      "Test F1: 0.373\n",
      "Top 10重要基因:\n",
      "                gene  importance\n",
      "436  ENSG00000256128    0.247274\n",
      "207  ENSG00000165887    0.214508\n",
      "76   ENSG00000119906    0.148828\n",
      "128  ENSG00000137877    0.140717\n",
      "77   ENSG00000119913    0.137659\n",
      "109  ENSG00000134283    0.136555\n",
      "239  ENSG00000172971    0.107555\n",
      "103  ENSG00000132182    0.101097\n",
      "261  ENSG00000181092    0.083348\n",
      "275  ENSG00000185551    0.082698\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='xgboost')\n",
    "\n",
    "# 1. 数据加载与合并（保持原有流程）\n",
    "meta = pd.read_csv(\n",
    "    \"./Data/GSE235508.meta.txt\",\n",
    "    sep='\\t',\n",
    "    quotechar='\"',\n",
    "    encoding='utf-8',\n",
    "    dtype=str\n",
    ")\n",
    "groups = meta[['geo_accession', 'samplegroup:ch1']].rename(\n",
    "    columns={'geo_accession': 'sample_title', 'samplegroup:ch1': 'group'}\n",
    ")\n",
    "\n",
    "expr = pd.read_csv(\n",
    "    \"./Data/GSE235508_mRNA_counts.txt\",\n",
    "    sep='\\t',\n",
    "    comment='!',\n",
    "    index_col=0,\n",
    "    encoding='utf-8'\n",
    ").T.reset_index().rename(columns={'index': 'sample_title'})\n",
    "\n",
    "merged = pd.merge(expr, groups, on='sample_title', how='inner')\n",
    "print(f\"Merged shape: {merged.shape}\")\n",
    "\n",
    "X = merged.drop(['sample_title', 'group'], axis=1).astype(float)\n",
    "y = merged['group']\n",
    "\n",
    "# 2. 标签编码（XGBoost需要从0开始的整数类别）\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 3. 数据预处理管道（移除标准化，树模型不需要）\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('variance_filter', VarianceThreshold(threshold=0.1*(1-0.1))),\n",
    "    ('selector', SelectKBest(f_classif, k=500)),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "])\n",
    "\n",
    "# 4. 划分训练测试集\n",
    "X_preprocessed = preprocessor.fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 5. 处理类别不平衡（XGBoost支持样本权重，但保持SMOTE流程）\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=10)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 6. 构建XGBoost模型管道\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('xgb', XGBClassifier(\n",
    "        objective='multi:softmax',  # 多分类目标函数\n",
    "        n_jobs=-1,\n",
    "        eval_metric='mlogloss',     # 多分类对数损失\n",
    "        early_stopping_rounds=10,   # 早停机制\n",
    "        use_label_encoder=False     # 禁用旧版标签编码\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 7. 超参数网格搜索\n",
    "param_grid = {\n",
    "    'xgb__n_estimators': [100, 200],\n",
    "    'xgb__max_depth': [3, 5, 7],\n",
    "    'xgb__learning_rate': [0.01, 0.1],\n",
    "    'xgb__subsample': [0.8, 1.0],\n",
    "    'xgb__colsample_bytree': [0.8, 1.0],\n",
    "    'xgb__gamma': [0, 0.1],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 8. 训练与调优（添加验证集用于早停）\n",
    "grid_search.fit(\n",
    "    X_train_res, y_train_res,\n",
    "    xgb__eval_set=[(X_test, y_test)]  # 早停监控验证集\n",
    ")\n",
    "\n",
    "# 9. 评估最佳模型\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Train F1: {best_model.score(X_train_res, y_train_res):.3f}\")\n",
    "print(f\"Test F1: {best_model.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# 10. 保存最佳模型\n",
    "joblib.dump(best_model, 'best_xgb_model.pkl')\n",
    "\n",
    "# 11. 特征重要性分析（基于树模型内置重要性）\n",
    "selected_idx = preprocessor.named_steps['selector'].get_support(indices=True)\n",
    "feature_names = X.columns[selected_idx]\n",
    "\n",
    "# 获取PCA前的特征重要性\n",
    "importances = best_model.named_steps['xgb'].feature_importances_\n",
    "pca_components = preprocessor.named_steps['pca'].components_\n",
    "\n",
    "# 映射回原始特征空间\n",
    "raw_importances = np.abs(pca_components.T @ importances).flatten()\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'gene': feature_names,\n",
    "    'importance': raw_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10重要基因:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9751466-1c86-4f6a-8fd8-657604b3f38a",
   "metadata": {},
   "source": [
    "## 2.5 Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ec754-e318-4423-927f-ccd4507baaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59dbf036-8e46-4731-b55e-08227d611438",
   "metadata": {},
   "source": [
    "## 2.6 PLS-DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e82b5-d9a6-4b51-bafd-781b7b078ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "013b5109-51b1-4761-839c-1a175650be1f",
   "metadata": {},
   "source": [
    "## 2.7 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e97b2b-6f88-4b00-a830-1d73b6020867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b10e15b-f38f-46e0-8357-79bb741d0ce2",
   "metadata": {},
   "source": [
    "## 2.8 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c54551-bdef-4cb4-a7b9-7ef92b22bab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a5d89d2-0fba-45f3-975a-68e4b4c87017",
   "metadata": {},
   "source": [
    "## 2.9 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2b831-49f6-4b75-8511-7e2b2072dd75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebfab969-1f0e-435e-ba70-871b8049c5ba",
   "metadata": {},
   "source": [
    "## 2.10 集成特征选择方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b88840-c9c2-4ff2-9ec7-c9724304116f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "865c4397-9c4b-40a2-b1c9-05a57cba7354",
   "metadata": {},
   "source": [
    "## 3.1 Logistic Regression + Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d14b1f-5ef2-443c-852c-e22b14ed071e",
   "metadata": {},
   "source": [
    "## 3.2 K-nearest neighbors(Knn) + Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6566b3-352b-4e53-8557-e81e1d0c2f64",
   "metadata": {},
   "source": [
    "## 3.3 Decision Trees + Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c99693-7219-43ee-b68f-1268c008ce09",
   "metadata": {},
   "source": [
    "## 3.4 Decision stump + Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254616b-2c0f-4394-9375-017069ce0e86",
   "metadata": {},
   "source": [
    "## 3.5 Random Forest + Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f368309-08f1-40cb-8f19-0e7ce721d4ed",
   "metadata": {},
   "source": [
    "## 3.6 AdaBoost + Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c72d5-b5af-4451-8042-71f640802717",
   "metadata": {},
   "source": [
    "## 3.7 XGBoost + Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d04ff-af13-49bc-8c9d-641c6698308e",
   "metadata": {},
   "source": [
    "## 3.8 LDA + Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6645313c-a625-4c59-8bd8-03ab6d78238e",
   "metadata": {},
   "source": [
    "## 3.9 Naive Bayes + Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add90b3f-21d0-4f58-9db3-09129694e4c4",
   "metadata": {},
   "source": [
    "## 3.10 Maximal Entropy Model + Breast Cancer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
